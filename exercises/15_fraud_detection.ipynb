{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('15_fraud_detection.csv.zip', 'r') as z:\n",
    "    f = z.open('15_fraud_detection.csv')\n",
    "    data = pd.io.parsers.read_table(f, index_col=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.Label.sum(), data.Label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 15.1\n",
    "\n",
    "Estimate a Logistic Regression and a Decision Tree\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.drop ('Label', axis=1)\n",
    "y=  data.Label\n",
    "\n",
    "# train/test split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for testing set\n",
    "y_pred_class = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993973645512\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "print(accuracy_score(y_pred_class, y_test))\n",
    "print(f1_score(y_test, y_pred_class))\n",
    "print(fbeta_score(y_test, y_pred_class,beta=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop ('Label', axis=1)\n",
    "y=  data.Label\n",
    "\n",
    "# train/test split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_reg = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for testing set\n",
    "y_pred_class = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989302499928\n",
      "0.147126436782\n",
      "0.15298684086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "print(accuracy_score(y_pred_class, y_test))\n",
    "print(f1_score(y_test, y_pred_class))\n",
    "print(fbeta_score(y_test, y_pred_class,beta=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que el f1 score y f beta score muestran que el arbolo de desición realizauna mejor prediccion de los fraudes comparado con la regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 15.2 (2 points)\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UnderSampling(X_train, y_train, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y_train.shape[0]\n",
    "    n_samples_0 = (y_train == 0).sum()\n",
    "    n_samples_1 = (y_train == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y_train == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y_train == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X_train[filter_], y_train[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.1\n",
      "y_train.shape =  5948 y_train.mean() =  0.0988567585743\n",
      "Target percentage 0.2\n",
      "y_train.shape =  2958 y_train.mean() =  0.19878296146\n",
      "Target percentage 0.3\n",
      "y_train.shape =  1931 y_train.mean() =  0.304505437597\n",
      "Target percentage 0.4\n",
      "y_train.shape =  1454 y_train.mean() =  0.404401650619\n",
      "Target percentage 0.5\n",
      "y_train.shape =  1181 y_train.mean() =  0.497883149873\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    X_u, y_u = UnderSampling(X_train, y_train, target_percentage, seed=12345)\n",
    "    print('Target percentage', target_percentage)\n",
    "    print('y_train.shape = ',y_u.shape[0], 'y_train.mean() = ', y_u.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_u, y_u=UnderSampling(X_train, y_train, 0.5, 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.fit(X_u, y_u)\n",
    "tree_reg.fit(X_u,y_u)\n",
    "\n",
    "y_pred_class_log_reg = log_reg.predict(X_test)\n",
    "y_pred_class_tree_reg = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994002479744\n",
      "0.988495141432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "print(accuracy_score(y_pred_class_log_reg, y_test))\n",
    "print(accuracy_score(y_pred_class_tree_reg, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 15.3 (2 points)\n",
    "\n",
    "Same analysis using TomekLinks and Condensed Nearest Neighbours\n",
    "\n",
    "Do not test different parameters for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=2, p=2, radius=1.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=2)\n",
    "nn.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nns = nn.kneighbors(X_train, return_distance=False)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the boolean result as false, and also a counter\n",
    "links = np.zeros(len(y_train), dtype=bool)\n",
    "\n",
    "# Loop through each sample of the majority class then we\n",
    "# look at its first neighbour. If its closest neighbour also has the\n",
    "# current sample as its closest neighbour, the two form a Tomek link.\n",
    "for ind, ele in enumerate(y_train):\n",
    "\n",
    "    if ele == 1 | links[ind] == True:  # Keep all from the minority class\n",
    "        continue\n",
    "\n",
    "    if y[nns[ind]] == 1:\n",
    "\n",
    "        # If they form a tomek link, put a True marker on this\n",
    "        # sample, and increase counter by one.\n",
    "        if nns[nns[ind]] == ind:\n",
    "            links[ind] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape =  103748 y_train.mean() =  0.00566757913406\n"
     ]
    }
   ],
   "source": [
    "filter_ = np.logical_not(links)\n",
    "print('y_train.shape = ',y_train[filter_].shape[0], 'y_train.mean() = ', y_train[filter_].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condensed Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop ('Label', axis=1)\n",
    "y= data.Label\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the K-NN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def CondensedNearestNeighbor(X_train, y_train, n_seeds_S=1, size_ngh=1, seed=None):\n",
    "    # Randomly get one sample from the majority class\n",
    "    np.random.seed(seed)\n",
    "    maj_sample = np.random.choice(X_train[y_train == 0].shape[0], n_seeds_S)\n",
    "    maj_sample = X_train[y_train == 0][maj_sample]\n",
    "    # Create the set C\n",
    "    # Select all positive and the randomly selected negatives\n",
    "    C_x = np.append(X_train[y_train == 1], maj_sample, axis=0)\n",
    "    C_y = np.append(y_train[y_train == 1], [0] * n_seeds_S)\n",
    "    # Create the set S\n",
    "    S_x = X_train[y_train == 0]\n",
    "    S_y = y_train[y_train == 0]\n",
    "    knn = KNeighborsClassifier(n_neighbors=size_ngh)\n",
    "\n",
    "    # Fit C into the knn\n",
    "    knn.fit(C_x, C_y)\n",
    "\n",
    "    # Classify on S\n",
    "    pred_S_y = knn.predict(S_x)\n",
    "    # Find the misclassified S_y\n",
    "    idx_tmp = np.nonzero(y_train == 0)[0][np.nonzero(pred_S_y != S_y)]\n",
    "\n",
    "    filter_ = np.nonzero(y_train == 1)[0]\n",
    "    filter_ = np.concatenate((filter_, idx_tmp), axis=0)\n",
    "\n",
    "    return X_train[filter_], y_train[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_seeds_S  1 size_ngh  1\n",
      "y_train.shape =  103890 y_train.mean() =  0.00566945808066\n",
      "n_seeds_S  100 size_ngh  100\n",
      "y_train.shape =  104040 y_train.mean() =  0.00566128412149\n",
      "n_seeds_S  50 size_ngh  50\n",
      "y_train.shape =  104040 y_train.mean() =  0.00566128412149\n",
      "n_seeds_S  100 size_ngh  50\n",
      "y_train.shape =  104040 y_train.mean() =  0.00566128412149\n",
      "n_seeds_S  50 size_ngh  100\n",
      "y_train.shape =  104040 y_train.mean() =  0.00566128412149\n"
     ]
    }
   ],
   "source": [
    "for n_seeds_S, size_ngh in [(1, 1), (100, 100), (50, 50), (100, 50), (50, 100)]:\n",
    "    X_u, y_u = CondensedNearestNeighbor(X_train, y_train, n_seeds_S, size_ngh, 1)\n",
    "    print('n_seeds_S ', n_seeds_S, 'size_ngh ', size_ngh)\n",
    "    print('y_train.shape = ',y_u.shape[0], 'y_train.mean() = ', y_u.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_u, y_u = CondensedNearestNeighbor(X_train, y_train, 1, 1, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.fit(X_u, y_u)\n",
    "tree_reg.fit(X_u,y_u)\n",
    "\n",
    "y_pred_class_log_reg = log_reg.predict(X_test)\n",
    "y_pred_class_tree_reg = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994002479744\n",
      "0.988120296416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "print(accuracy_score(y_pred_class_log_reg, y_test))\n",
    "print(accuracy_score(y_pred_class_tree_reg, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 15.4 \n",
    "\n",
    "Now using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X_train, y_train, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y_train.shape[0]\n",
    "    n_samples_0 = (y_train == 0).sum()\n",
    "    n_samples_1 = (y_train == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X_train[y_train == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y_train == 0)[0]), axis=0)\n",
    "    \n",
    "    return X_train[filter_], y_train[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.1\n",
      "y_train.shape =  114945 y_train.mean() =  0.000400191395885\n",
      "Target percentage 0.2\n",
      "y_train.shape =  129313 y_train.mean() =  0.000966646818185\n",
      "Target percentage 0.3\n",
      "y_train.shape =  147787 y_train.mean() =  0.00145479643\n",
      "Target percentage 0.4\n",
      "y_train.shape =  172418 y_train.mean() =  0.00193135287499\n",
      "Target percentage 0.5\n",
      "y_train.shape =  206902 y_train.mean() =  0.00248910112034\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    X_u, y_u = OverSampling(X_train, y_train, target_percentage, 12345)\n",
    "    print('Target percentage', target_percentage)\n",
    "    print('y_train.shape = ',y_u.shape[0], 'y_train.mean() = ', y_u.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " X_u, y_u = OverSampling(X_train, y_train,0.5,12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.fit(X_u, y_u)\n",
    "tree_reg.fit(X_u,y_u)\n",
    "\n",
    "y_pred_class_log_reg = log_reg.predict(X_test)\n",
    "y_pred_class_tree_reg = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994002479744\n",
      "0.988120296416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "print(accuracy_score(y_pred_class_log_reg, y_test))\n",
    "print(accuracy_score(y_pred_class_tree_reg, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = y_train.shape[0]\n",
    "n_samples_0 = (y_train == 0).sum()\n",
    "n_samples_1 = (y_train == 1).sum()\n",
    "def SMOTE(X_train, y_train, target_percentage=0.5, k=5, seed=None):\n",
    "    \n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X_train.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y_train[y_train==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__ = np.random.choice(k, n_samples_1_new)\n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X_train[y_train==1][sel] - step * (X_train[y_train==1][sel] - X_train[y_train==1][nn_])\n",
    "    \n",
    "    X_train = np.vstack((X_train, new))\n",
    "    y_train = np.append(y_train, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.25 k  5\n",
      "y.shape =  137934 y.mean() =  0.249996375078\n",
      "Target percentage 0.25 k  15\n",
      "y.shape =  137934 y.mean() =  0.249996375078\n",
      "Target percentage 0.5 k  5\n",
      "y.shape =  206902 y.mean() =  0.5\n",
      "Target percentage 0.5 k  15\n",
      "y.shape =  206902 y.mean() =  0.5\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.25, 0.5]:\n",
    "    for k in [5, 15]:\n",
    "        X_u, y_u = SMOTE(X_train, y_train, target_percentage, k, seed=12345)\n",
    "        print('Target percentage', target_percentage, 'k ', k)\n",
    "        print('y.shape = ',y_u.shape[0], 'y.mean() = ', y_u.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_u, y_u = SMOTE(X_train, y_train, 0.5, 5, 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.fit(X_u, y_u)\n",
    "tree_reg.fit(X_u,y_u)\n",
    "\n",
    "y_pred_class_log_reg = log_reg.predict(X_test)\n",
    "y_pred_class_tree_reg = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709033764886\n",
      "0.986505579424\n",
      "0.0154161381598\n",
      "0.093023255814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "print(accuracy_score(y_pred_class_log_reg, y_test))\n",
    "print(accuracy_score(y_pred_class_tree_reg, y_test))\n",
    "print(f1_score(y_pred_class_log_reg, y_test))\n",
    "print(f1_score(y_pred_class_tree_reg, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dado que el accurancy no es un buen indicador en este caso dado que la base de datos presenta menor cantidad de reportes de fraude (1) comparado con los que no son fraude (0), puesto que los modelos anteriores predicen casi todo como 0 y es por esto que el accurancy no es confiable. Para corregir este error es necesario realizar esta comparación mediante el f1 score y se observa que el modelo mas apropiado corresponde al arbol de desición en el modelo SMOTE, una de las ventajas de este modelo es que nos permite añadir nueva información para realizar las estimaciones. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
