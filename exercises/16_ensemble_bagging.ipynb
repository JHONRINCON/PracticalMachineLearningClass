{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/09/16/sprints-upgrade...</td>\n",
       "      <td>479</td>\n",
       "      <td>11</td>\n",
       "      <td>1045</td>\n",
       "      <td>0.407946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.305139</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2014/12/06/eric-garner-pro...</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/06/06/human-scale-inv...</td>\n",
       "      <td>581</td>\n",
       "      <td>6</td>\n",
       "      <td>604</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675516</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.215873</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2014/11/24/beyonce-spotify...</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>708</td>\n",
       "      <td>0.474286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.376852</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/03/03/superheroic-let...</td>\n",
       "      <td>676</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/09/16/sprints-upgrade...        479   \n",
       "1  http://mashable.com/2014/12/06/eric-garner-pro...         31   \n",
       "2  http://mashable.com/2013/06/06/human-scale-inv...        581   \n",
       "3  http://mashable.com/2014/11/24/beyonce-spotify...         44   \n",
       "4  http://mashable.com/2013/03/03/superheroic-let...        676   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0              11              1045         0.407946                 1   \n",
       "1              14                 0         0.000000                 0   \n",
       "2               6               604         0.470000                 1   \n",
       "3              16               708         0.474286                 1   \n",
       "4               7                30         1.000000                 1   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.617021         29               3         1   ...      \n",
       "1                  0.000000          0               0         0   ...      \n",
       "2                  0.675516          9               0         1   ...      \n",
       "3                  0.675325          5               2         2   ...      \n",
       "4                  1.000000          2               1         0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.033333                    1.0              -0.305139   \n",
       "1               0.000000                    0.0               0.000000   \n",
       "2               0.100000                    1.0              -0.215873   \n",
       "3               0.062500                    0.5              -0.376852   \n",
       "4               0.250000                    0.7               0.000000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0              -0.700000              -0.125000                 0.0   \n",
       "1               0.000000               0.000000                 1.0   \n",
       "2              -0.666667              -0.071429                 0.1   \n",
       "3              -0.875000              -0.100000                 0.4   \n",
       "4               0.000000               0.000000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.0                     0.5   \n",
       "1                      -0.5                     0.5   \n",
       "2                       0.0                     0.4   \n",
       "3                      -0.2                     0.1   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.0        1  \n",
       "1                           0.5        0  \n",
       "2                           0.0        0  \n",
       "3                           0.2        0  \n",
       "4                           0.0        1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv('14_mashable_train_df.csv', index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23786, 61)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 16.1 (2 points)\n",
    "\n",
    "Estimate a Logistic Regression, GaussianNB, K-nearest neighbors and a Decision Tree **Classifiers**\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=2)\n",
    "\n",
    "Comment about the results\n",
    "\n",
    "Combine the classifiers and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {'lr': LogisticRegression(),\n",
    "          'nb': GaussianNB(),\n",
    "          'nn': KNeighborsClassifier(),\n",
    "          'dt': DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular'].values\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn Accuracy 0.857070791996\n",
      "lr Accuracy 0.871363712796\n",
      "dt Accuracy 0.774340003363\n",
      "nb Accuracy 0.839246678998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for model in models.keys():\n",
    "    print(model, 'Accuracy', accuracy_score(y_pred[model],y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn F1_Score 0.0597345132743\n",
      "lr F1_Score 0.0103492884864\n",
      "dt F1_Score 0.190591073583\n",
      "nb F1_Score 0.153982300885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "for model in models.keys():\n",
    "    print(model, 'F1_Score',f1_score(y_pred[model],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn F_Beta_Score 0.100596125186\n",
      "lr F_Beta_Score 0.0244498777506\n",
      "dt F_Beta_Score 0.181275814594\n",
      "nb F_Beta_Score 0.193677649154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "for model in models.keys():\n",
    "    print(model, 'F_Beta_Score',fbeta_score(y_pred[model],y_test,beta=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que todos los modelos presentan buen accuracy siendo la regresión logistica la que mejor ajuste presenta y el arbol de clasificación el de menor, sin embargo en cuanto al F1 score y el Fbeta score es bajo, dado que estos modelos presentan una presición baja en cuanto al porcentaje de resultados positivos obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 16.2\n",
    "\n",
    "Apply random-undersampling with a target percentage of 0.5\n",
    "\n",
    "how does the results change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UnderSampling(X_train, y_train, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y_train.shape[0]\n",
    "    n_samples_0 = (y_train == 0).sum()\n",
    "    n_samples_1 = (y_train == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y_train == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y_train == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X_train[filter_], y_train[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_u, y_u=UnderSampling(X_train, y_train, 0.5, 123)\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_u, y_u)\n",
    "    \n",
    "# predict test for each model\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn Accuracy 0.581469648562\n",
      "lr Accuracy 0.660669244997\n",
      "dt Accuracy 0.571212375988\n",
      "nb Accuracy 0.823608542122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "for model in models.keys():\n",
    "    print(model, 'Accuracy',accuracy_score(y_pred[model],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn F1_Score 0.249170437406\n",
      "lr F1_Score 0.302213001383\n",
      "dt F1_Score 0.250440917108\n",
      "nb F1_Score 0.196168582375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "for model in models.keys():\n",
    "    print(model, 'F1_Score',f1_score(y_pred[model],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn F_Beta_Score 0.187966502822\n",
      "lr F_Beta_Score 0.235097912632\n",
      "dt F_Beta_Score 0.187930121758\n",
      "nb F_Beta_Score 0.217243720299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "for model in models.keys():\n",
    "    print(model, 'F_Beta_Score',fbeta_score(y_pred[model],y_test,beta=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que al balancear la base de datos mediante un muetreo sobre las categorias que presentan mayor ocurrencia, es decir sobre las calificaciones del articulo como no popular (0), se obtiene que todos los modelos anteriormente estimados presentan  una disminución en su accuracy debido a que estos estaban prediciendo erradamente los articulos populares, sin embargo se tiene que al realizar este balanceo el F1_Score y el F_Beta_Score aumentan con relación a las estimaciones que se obtuvieron con la base de datos desbalanceada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 16.3 (3 points)\n",
    "\n",
    "For each model estimate a BaggingClassifier of 100 models using the under sampled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=None,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagreg = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagreg.fit(X_u, y_u)\n",
    "y_pred = bagreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "Accuracy = accuracy_score(y_pred, y_test)\n",
    "F1_Score= f1_score(y_pred, y_test)\n",
    "F_Beta_Score = fbeta_score(y_pred, y_test,beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.64385404405582647, 0.31633311814073595, 0.24214271595176912)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy, F1_Score ,F_Beta_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 16.4 (2 points)\n",
    "\n",
    "Using the under-sampled dataset\n",
    "\n",
    "Evaluate a RandomForestClassifier and compare the results\n",
    "\n",
    "change n_estimators=100, what happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=-1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcla = RandomForestClassifier(n_estimators=150, oob_score=True, random_state=1, n_jobs=-1)\n",
    "rfcla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfcla.fit(X_u, y_u)\n",
    "y_pred = rfcla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "Accuracy = accuracy_score(y_pred, y_test)\n",
    "F1_Score= f1_score(y_pred, y_test)\n",
    "F_Beta_Score = fbeta_score(y_pred, y_test,beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65041197242307047, 0.32827140549273021, 0.2513358400949931)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy, F1_Score ,F_Beta_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcla = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=1, n_jobs=-1)\n",
    "rfcla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfcla.fit(X_u, y_u)\n",
    "y_pred = rfcla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "Accuracy = accuracy_score(y_pred, y_test)\n",
    "F1_Score= f1_score(y_pred, y_test)\n",
    "F_Beta_Score = fbeta_score(y_pred, y_test,beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6488986043383218, 0.32251784555483448, 0.24716530734036204)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy, F1_Score ,F_Beta_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que las predicciones realizadas mediante randonforest presenta mayor presición con relación a los modelos que se ajustaron inicialmente (nn, lr, nb, dt), y se observa que al disminuir la cantidad de arboles de 150 a 100 el ajuste disminuye levemente en su Accuracy, F1_Score y F_Beta_Score por lo que se puede afirmar que entre mayores combinaciones de arboles se realicen sus predicciones aumentaran en su presición."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
